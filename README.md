# å…¨æ¯æ•°å­—äººç›´æ’­ç³»ç»Ÿ (Holographic Digital Human Livestreaming System)

A comprehensive multilingual holographic digital human livestreaming system with AI-powered interactions, real-time motion capture, and cross-platform streaming capabilities.

## ğŸŒŸ Features

- **ğŸ¤– AI-Powered Digital Humans**: Multi-modal AI generation with personality memory
- **ğŸ­ Real-time 3D Animation**: Motion capture integration with facial expressions
- **ğŸŒ 12-Language Support**: Real-time translation and lip-sync technology
- **ğŸ“¹ Live Streaming**: 7Ã—24 continuous streaming for e-commerce
- **ğŸ’¬ Interactive Chat**: Real-time viewer engagement with AI responses
- **ğŸ¨ Emotion Control**: Dynamic emotional expressions and reactions

## ğŸ—ï¸ Architecture

### Core Components

1. **PIAPI MCP Server** (`apinetwork/piapi-mcp-server`)
   - Multimodal AI content generation
   - Text, image, and video processing

2. **Screenpipe** (`mediar-ai/screenpipe`)
   - Real-time motion capture
   - Skeletal tracking and facial recognition

3. **Mem0 MCP** (`mem0ai/mem0-mcp`)
   - Personality memory database
   - Consistent character behavior

4. **Lara MCP** (`translated/lara-mcp`)
   - Multilingual lip-sync
   - Real-time phoneme generation

### Technology Stack

- **Frontend**: Next.js 15, React 18, TypeScript
- **3D Rendering**: Three.js, React Three Fiber
- **Styling**: Tailwind CSS, Framer Motion
- **Real-time**: Socket.IO, WebSocket
- **State Management**: React Hooks

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ 
- npm or yarn
- WebCamera (for motion capture)
- Microphone (for voice input)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd multilingual-holo-bot
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start development server**
   ```bash
   npm run dev
   ```

4. **Open in browser**
   ```
   http://localhost:3000
   ```

### Environment Setup

Create a `.env.local` file:

```env
# MCP Server Endpoints
PIAPI_MCP_URL=ws://localhost:8001
SCREENPIPE_MCP_URL=ws://localhost:8002
MEM0_MCP_URL=ws://localhost:8003
LARA_MCP_URL=ws://localhost:8004

# API Keys (when using real services)
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
```

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”œâ”€â”€ page.tsx           # Main application page
â”‚   â””â”€â”€ layout.tsx         # Root layout
â”œâ”€â”€ components/            # React components
â”‚   â”œâ”€â”€ 3d/               # 3D rendering components
â”‚   â”œâ”€â”€ controls/         # Control panels
â”‚   â”œâ”€â”€ streaming/        # Streaming interfaces
â”‚   â””â”€â”€ ui/               # UI components
â”œâ”€â”€ services/             # MCP clients and services
â”‚   â”œâ”€â”€ mcp-clients.ts    # Individual MCP clients
â”‚   â””â”€â”€ mcp-manager.ts    # Service orchestration
â”œâ”€â”€ types/                # TypeScript definitions
â”œâ”€â”€ hooks/                # Custom React hooks
â”œâ”€â”€ lib/                  # Utilities and configurations
â”œâ”€â”€ stores/               # State management
â””â”€â”€ utils/                # Helper functions
```

## ğŸ® Usage

### Basic Operation

1. **Start the Application**
   - Launch the dev server: `npm run dev`
   - Open browser to http://localhost:3000

2. **Configure Avatar**
   - Select language (12 supported)
   - Set personality traits
   - Adjust appearance settings

3. **Begin Streaming**
   - Click "Start Streaming"
   - Enable camera/microphone
   - Start interacting with viewers

## ğŸ”§ Development Status

### âœ… Completed
- [x] Project setup with Next.js 15 + TypeScript
- [x] 3D avatar system with Three.js
- [x] MCP service integration layer
- [x] Real-time chat interface
- [x] Streaming control panel
- [x] Type-safe architecture
- [x] Basic emotion system

### ğŸš§ In Progress  
- [ ] MCP server deployment
- [ ] Motion capture integration
- [ ] Voice synthesis
- [ ] Production optimization

### ğŸ“‹ TODO
- [ ] Add 3D models and textures
- [ ] Deploy MCP servers
- [ ] Audio streaming pipeline
- [ ] Performance optimization
- [ ] Production deployment

## ğŸ§ª Demo Mode

The application currently runs in demo mode with:
- Mock MCP responses
- Simulated motion capture
- Basic 3D avatar
- Interactive controls

## ğŸ“š Next Steps

1. **Setup MCP Servers**: Deploy and configure the 4 MCP servers
2. **3D Assets**: Add realistic avatar models and animations  
3. **Audio Integration**: Implement voice synthesis and streaming
4. **Performance**: Optimize for real-time processing
5. **Deployment**: Production environment setup
